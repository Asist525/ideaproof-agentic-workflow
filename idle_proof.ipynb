{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 0) Install & Imports\n",
        "\n",
        "> Colab 기준. 이미 API 키는 Colab userdata / 환경변수에 세팅되어 있다고 가정합니다."
      ],
      "metadata": {
        "id": "xzNg-ZEuZ3i1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bjd8IhRB_a8c"
      },
      "outputs": [],
      "source": [
        "#!pip -q install -U openai==1.81.0 langgraph langchain-upstage langchain-community chromadb transformers python-dotenv pydantic rich\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install chromadb"
      ],
      "metadata": {
        "id": "OS-8JvtqAlgj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip -q install -U trafilatura readability-lxml beautifulsoup4 lxml"
      ],
      "metadata": {
        "id": "Dls-Qwp_GvEy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, json, time, math, re, hashlib, textwrap\n",
        "from dataclasses import dataclass\n",
        "from typing import Any, Dict, List, Optional, Tuple, TypedDict, Literal\n",
        "\n",
        "import requests\n",
        "from dotenv import load_dotenv\n",
        "from pydantic import BaseModel, Field, ValidationError\n",
        "\n",
        "from openai import OpenAI\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "import chromadb\n",
        "from chromadb import Documents, EmbeddingFunction, Embeddings, PersistentClient\n",
        "\n",
        "from rich import print as rprint\n"
      ],
      "metadata": {
        "id": "ohhwskpw_e4Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1) API Keys & Clients\n",
        "\n",
        "- `UPSTAGE_API_KEY`, `SERPER_API_KEY`는 **이미 등록되어 있고 변수명도 동일**하다고 했으니 그대로 씁니다.\n",
        "- 모델 라인업(예시):  \n",
        "  - Solar: `solar-pro2-250909`  \n",
        "  - Document Parse: `document-parse-250618`  \n",
        "  - Embedding: `solar-embedding-1-large-query`\n"
      ],
      "metadata": {
        "id": "qD1ApIMmZ8Of"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "load_dotenv()\n",
        "\n",
        "UPSTAGE_API_KEY = os.getenv(\"UPSTAGE_API_KEY\")\n",
        "SERPER_API_KEY  = os.getenv(\"SERPER_API_KEY\")\n",
        "DART_API_KEY    = os.getenv(\"DART_API_KEY\")  # 선택(없어도 동작)\n",
        "\n",
        "# Colab userdata (선택)\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    UPSTAGE_API_KEY = UPSTAGE_API_KEY or userdata.get(\"UPSTAGE_API_KEY\")\n",
        "    SERPER_API_KEY  = SERPER_API_KEY  or userdata.get(\"SERPER_API_KEY\")\n",
        "    DART_API_KEY    = DART_API_KEY    or userdata.get(\"DART_API_KEY\")\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "assert UPSTAGE_API_KEY, \"UPSTAGE_API_KEY not found\"\n",
        "assert SERPER_API_KEY, \"SERPER_API_KEY not found\"\n",
        "\n",
        "client = OpenAI(base_url=\"https://api.upstage.ai/v1\", api_key=UPSTAGE_API_KEY)\n",
        "\n",
        "# 토큰 추정용 (HF 토크나이저는 model_max_length=4096 경고가 뜨는 경우가 많아서 무력화)\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"upstage/solar-pro-preview-instruct\")\n",
        "tokenizer.model_max_length = 1_000_000\n",
        "\n",
        "# Solar-Pro2 컨텍스트(≈64K) 안전값\n",
        "MAX_CONTEXT_LIMIT = 65000\n",
        "\n",
        "# Vector DB\n",
        "CHROMA_PATH = \"./chroma_db_ideaproof\"\n",
        "chroma_client = PersistentClient(path=CHROMA_PATH)\n"
      ],
      "metadata": {
        "id": "Yja_3FH5A4KF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2) Shared Utils (schema, tool runner, token budget)\n",
        "\n",
        "- Upstage Solar-Pro 계열은 컨텍스트가 대략 64K 수준이므로, 안전한 한계치로 60K를 사용합니다.\n"
      ],
      "metadata": {
        "id": "dA7zUBRaaA5S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import inspect\n",
        "\n",
        "def function_to_schema(func) -> dict:\n",
        "    sig = inspect.signature(func)\n",
        "    props = {}\n",
        "    required = []\n",
        "    for name, param in sig.parameters.items():\n",
        "        if name in (\"self\",):\n",
        "            continue\n",
        "        ann = param.annotation\n",
        "        jtype = \"string\"\n",
        "        if ann in (int,):\n",
        "            jtype = \"integer\"\n",
        "        elif ann in (float,):\n",
        "            jtype = \"number\"\n",
        "        elif ann in (bool,):\n",
        "            jtype = \"boolean\"\n",
        "        elif ann in (list, List):\n",
        "            jtype = \"array\"\n",
        "        elif ann in (dict, Dict):\n",
        "            jtype = \"object\"\n",
        "        props[name] = {\"type\": jtype}\n",
        "        if param.default is inspect._empty:\n",
        "            required.append(name)\n",
        "    return {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": func.__name__,\n",
        "            \"description\": (func.__doc__ or \"\").strip(),\n",
        "            \"parameters\": {\"type\": \"object\", \"properties\": props, \"required\": required}\n",
        "        }\n",
        "    }\n",
        "\n",
        "def truncate_tokens_if_needed(tokenizer, agent_instructions, messages, content, max_token_limit=None):\n",
        "    \"\"\"\n",
        "    - base가 이미 limit을 넘으면(히스토리 과다) 에러 내지 말고 내용을 최소화해서 계속 진행\n",
        "    - content가 넘치면 content만 잘라서 limit 안으로 넣기\n",
        "    \"\"\"\n",
        "    if max_token_limit is None:\n",
        "        max_token_limit = MAX_CONTEXT_LIMIT\n",
        "\n",
        "    inputs = tokenizer.apply_chat_template(\n",
        "        [{\"role\": \"system\", \"content\": agent_instructions}] + messages,\n",
        "        tokenize=True\n",
        "    )\n",
        "    base_tokens = len(inputs)\n",
        "\n",
        "    if base_tokens >= max_token_limit:\n",
        "        return \"[...omitted due to context budget...]\"\n",
        "\n",
        "    enc = tokenizer.encode(content)\n",
        "    if base_tokens + len(enc) > max_token_limit:\n",
        "        keep = max_token_limit - base_tokens\n",
        "        enc = enc[:max(0, keep)]\n",
        "        content = tokenizer.decode(enc, skip_special_tokens=True) + \"\\n\\n[...Content Truncated due to Context Limit...]\"\n",
        "    return content\n",
        "\n",
        "def execute_tool_call(tool_name: str, tools: Dict[str, Any], args: Dict[str, Any]) -> str:\n",
        "    if tool_name not in tools:\n",
        "        raise KeyError(f\"Tool not found: {tool_name}\")\n",
        "    return tools[tool_name](**args)\n",
        "\n",
        "def safe_json_loads(s: str) -> Any:\n",
        "    s = s.strip()\n",
        "    try:\n",
        "        return json.loads(s)\n",
        "    except Exception:\n",
        "        pass\n",
        "    s2 = re.sub(r\"^```(json)?\\s*|\\s*```$\", \"\", s, flags=re.MULTILINE).strip()\n",
        "    try:\n",
        "        return json.loads(s2)\n",
        "    except Exception:\n",
        "        pass\n",
        "    m = re.search(r\"(\\{.*\\}|\\[.*\\])\", s2, flags=re.DOTALL)\n",
        "    if not m:\n",
        "        raise ValueError(\"No JSON object found in text\")\n",
        "    return json.loads(m.group(1))\n",
        "\n",
        "def hash_key(*parts: str) -> str:\n",
        "    h = hashlib.sha256()\n",
        "    for p in parts:\n",
        "        h.update(p.encode(\"utf-8\"))\n",
        "    return h.hexdigest()[:16]\n"
      ],
      "metadata": {
        "id": "8tpd2yziBJiE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3) Core Tools\n",
        "\n",
        "필수 Tool 기능:\n",
        "1) 인터넷 검색(serper.dev)  \n",
        "2) 인터넷 파일 다운로드  \n",
        "3) PDF → Markdown 파싱(Upstage Document Parse)  \n",
        "4) Vector DB 저장/조회(Chroma + Upstage embedding)  \n",
        "5) LLM-as-Judge Rerank (Top-K 재정렬)\n",
        "\n",
        "> 한국 기업/시장 분석을 우선하기 위해 검색 쿼리에 한국 소스 힌트를 자동으로 섞습니다.\n"
      ],
      "metadata": {
        "id": "rnCFK7GlaDtR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "import time\n",
        "import trafilatura\n",
        "from urllib.parse import urlparse\n",
        "\n",
        "logging.getLogger(\"trafilatura\").setLevel(logging.ERROR)\n",
        "logging.getLogger(\"trafilatura.core\").setLevel(logging.ERROR)\n",
        "logging.getLogger(\"trafilatura.utils\").setLevel(logging.ERROR)\n",
        "\n",
        "def web_search(query: str, k: int = 10) -> List[Dict[str, str]]:\n",
        "    url = \"https://google.serper.dev/search\"\n",
        "    payload = json.dumps({\"q\": query, \"num\": k})\n",
        "    headers = {\"X-API-KEY\": SERPER_API_KEY, \"Content-Type\": \"application/json\"}\n",
        "    r = requests.post(url, headers=headers, data=payload, timeout=60)\n",
        "    r.raise_for_status()\n",
        "    data = r.json()\n",
        "    out = []\n",
        "    for item in data.get(\"organic\", [])[:k]:\n",
        "        out.append({\"title\": item.get(\"title\",\"\"), \"link\": item.get(\"link\",\"\"), \"snippet\": item.get(\"snippet\",\"\")})\n",
        "    return out\n",
        "\n",
        "def is_pdf_url(url: str) -> bool:\n",
        "    return url.lower().split(\"?\")[0].endswith(\".pdf\")\n",
        "\n",
        "def fetch_url_text(url: str, timeout: int = 30, max_chars: int = 30000) -> str:\n",
        "    try:\n",
        "        r = requests.get(\n",
        "            url,\n",
        "            timeout=timeout,\n",
        "            headers={\"User-Agent\":\"Mozilla/5.0\"},\n",
        "            allow_redirects=True,\n",
        "        )\n",
        "        r.raise_for_status()\n",
        "\n",
        "        ctype = (r.headers.get(\"content-type\") or \"\").lower()\n",
        "        if (\"text/html\" not in ctype) and (\"application/xhtml\" not in ctype):\n",
        "            return \"\"\n",
        "\n",
        "        html = (r.text or \"\").strip()\n",
        "        if len(html) < 200:\n",
        "            return \"\"\n",
        "\n",
        "        text = trafilatura.extract(html, include_comments=False, include_tables=False, favor_recall=True) or \"\"\n",
        "        text = text.strip()\n",
        "        if len(text) > max_chars:\n",
        "            text = text[:max_chars]\n",
        "        return text\n",
        "    except Exception:\n",
        "        return \"\"\n",
        "\n",
        "def source_priority_score(url: str) -> int:\n",
        "    host = (urlparse(url).netloc or \"\").lower()\n",
        "    score = 0\n",
        "    if host.endswith(\".go.kr\"): score += 50\n",
        "    if host.endswith(\".ac.kr\"): score += 35\n",
        "    if host.endswith(\".or.kr\"): score += 25\n",
        "    if host.endswith(\".re.kr\"): score += 20\n",
        "    if host.endswith(\".kr\"): score += 10\n",
        "    if \"kosis\" in host or \"kostat\" in host: score += 50\n",
        "    if \"dart\" in host or \"fss\" in host: score += 40\n",
        "    if \"nipa\" in host or \"kisdi\" in host or \"kised\" in host: score += 25\n",
        "    return score\n",
        "\n",
        "def download_file(url: str, save_dir: str = \"./downloads\") -> str:\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "    fn = re.sub(r\"[^a-zA-Z0-9_.-]\", \"_\", url.split(\"/\")[-1]) or f\"file_{int(time.time())}\"\n",
        "    path = os.path.join(save_dir, fn)\n",
        "    r = requests.get(url, timeout=120, headers={\"User-Agent\":\"Mozilla/5.0\"}, allow_redirects=True)\n",
        "    r.raise_for_status()\n",
        "    with open(path, \"wb\") as f:\n",
        "        f.write(r.content)\n",
        "    return path\n",
        "\n",
        "def parse_pdf_to_markdown(pdf_path: str) -> str:\n",
        "    url = \"https://api.upstage.ai/v1/document-ai/document-parse\"\n",
        "    headers = {\"Authorization\": f\"Bearer {UPSTAGE_API_KEY}\"}\n",
        "    with open(pdf_path, \"rb\") as f:\n",
        "        files = {\"document\": f}\n",
        "        data = {\n",
        "            \"model\": \"document-parse-250618\",\n",
        "            \"ocr\": \"auto\",\n",
        "            \"chart_recognition\": True,\n",
        "            \"coordinates\": True,\n",
        "            \"output_formats\": '[\"markdown\"]',\n",
        "            \"base64_encoding\": '[\"figure\"]',\n",
        "        }\n",
        "        r = requests.post(url, headers=headers, files=files, data=data, timeout=180)\n",
        "        r.raise_for_status()\n",
        "        j = r.json()\n",
        "    return j.get(\"content\", {}).get(\"markdown\", \"\")\n",
        "\n",
        "def _normalize_for_embedding(x: Any, max_chars: int = 8000) -> str:\n",
        "    s = (x if isinstance(x, str) else str(x) if x is not None else \"\").replace(\"\\x00\", \"\").strip()\n",
        "    if not s:\n",
        "        return \"\"\n",
        "    if len(s) > max_chars:\n",
        "        s = s[:max_chars]\n",
        "    return s\n",
        "\n",
        "class UpstageEmbeddingFunction(EmbeddingFunction):\n",
        "    def __init__(\n",
        "        self,\n",
        "        client: OpenAI,\n",
        "        model: str = \"solar-embedding-1-large-query\",\n",
        "        batch_size: int = 16,\n",
        "        max_chars: int = 8000,\n",
        "        retries: int = 1,\n",
        "        backoff_sec: float = 1.0,\n",
        "    ):\n",
        "        self.client = client\n",
        "        self.model = model\n",
        "        self.batch_size = batch_size\n",
        "        self.max_chars = max_chars\n",
        "        self.retries = retries\n",
        "        self.backoff_sec = backoff_sec\n",
        "\n",
        "    def _embed_batch(self, texts: List[str]) -> List[List[float]]:\n",
        "        last_err = None\n",
        "        for attempt in range(self.retries + 1):\n",
        "            try:\n",
        "                resp = self.client.embeddings.create(model=self.model, input=texts)\n",
        "                return [d.embedding for d in resp.data]\n",
        "            except Exception as e:\n",
        "                last_err = e\n",
        "                if attempt < self.retries:\n",
        "                    time.sleep(self.backoff_sec * (attempt + 1))\n",
        "        raise last_err\n",
        "\n",
        "    def _embed_one(self, text: str) -> List[float]:\n",
        "        resp = self.client.embeddings.create(model=self.model, input=text)\n",
        "        return resp.data[0].embedding\n",
        "\n",
        "    def __call__(self, input: Documents) -> Embeddings:\n",
        "        if isinstance(input, str):\n",
        "            t = _normalize_for_embedding(input, max_chars=self.max_chars)\n",
        "            return [self._embed_one(t)] if t else [self._embed_one(\".\")]\n",
        "\n",
        "        raw = [_normalize_for_embedding(t, max_chars=self.max_chars) for t in list(input)]\n",
        "        texts = [t if t else \".\" for t in raw]\n",
        "\n",
        "        out: List[List[float]] = []\n",
        "        i = 0\n",
        "        while i < len(texts):\n",
        "            batch = texts[i:i+self.batch_size]\n",
        "            try:\n",
        "                out.extend(self._embed_batch(batch))\n",
        "            except Exception:\n",
        "                for t in batch:\n",
        "                    out.append(self._embed_one(t if t else \".\"))\n",
        "            i += self.batch_size\n",
        "        return out\n",
        "\n",
        "embedding_fn = UpstageEmbeddingFunction(client)\n",
        "\n",
        "def get_collection(name: str):\n",
        "    return chroma_client.get_or_create_collection(name=name, embedding_function=embedding_fn)\n",
        "\n",
        "def vectordb_upsert(collection: str, docs: List[str], metadatas: List[Dict[str, Any]], ids: List[str]) -> int:\n",
        "    clean_docs, clean_metas, clean_ids = [], [], []\n",
        "    for d, m, i in zip(docs, metadatas, ids):\n",
        "        s = _normalize_for_embedding(d, max_chars=8000)\n",
        "        if not s:\n",
        "            continue\n",
        "        clean_docs.append(s)\n",
        "        clean_metas.append(m)\n",
        "        clean_ids.append(i)\n",
        "\n",
        "    if not clean_ids:\n",
        "        return 0\n",
        "\n",
        "    col = get_collection(collection)\n",
        "    col.upsert(documents=clean_docs, metadatas=clean_metas, ids=clean_ids)\n",
        "    return len(clean_ids)\n",
        "\n",
        "def vectordb_query(collection: str, query: str, n_results: int = 8) -> Dict[str, Any]:\n",
        "    col = get_collection(collection)\n",
        "    return col.query(query_texts=[query], n_results=n_results)\n",
        "\n",
        "def llm_rerank(query: str, candidates: List[Dict[str, Any]], top_k: int = 5) -> List[Dict[str, Any]]:\n",
        "    packed = [{\"i\": i, \"text\": (c.get(\"text\",\"\")[:1200]), \"meta\": c.get(\"meta\",{})} for i,c in enumerate(candidates)]\n",
        "    prompt = {\n",
        "        \"task\": \"rerank\",\n",
        "        \"instruction\": \"You are a strict relevance judge. Score 0-10 by relevance. Prefer authoritative Korea-specific sources.\",\n",
        "        \"query\": query,\n",
        "        \"candidates\": packed\n",
        "    }\n",
        "    resp = client.chat.completions.create(\n",
        "        model=\"solar-pro2-250909\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"Return JSON only.\"},\n",
        "            {\"role\": \"user\", \"content\": json.dumps(prompt, ensure_ascii=False)}\n",
        "        ],\n",
        "    )\n",
        "    data = safe_json_loads(resp.choices[0].message.content)\n",
        "    scored = data.get(\"scores\", data)\n",
        "    merged = []\n",
        "    for item in scored:\n",
        "        i = int(item[\"i\"])\n",
        "        merged.append({**candidates[i], \"score\": float(item.get(\"score\", 0)), \"reason\": item.get(\"reason\",\"\")})\n",
        "    merged.sort(key=lambda x: x[\"score\"], reverse=True)\n",
        "    return merged[:top_k]\n",
        "\n",
        "def simple_chunk(text: str, max_chars: int = 1500, overlap: int = 200) -> List[str]:\n",
        "    text = (text or \"\").strip()\n",
        "    if not text:\n",
        "        return []\n",
        "    chunks = []\n",
        "    i = 0\n",
        "    step = max(1, max_chars - overlap)\n",
        "    while i < len(text):\n",
        "        c = text[i:i+max_chars].strip()\n",
        "        if c:\n",
        "            chunks.append(c)\n",
        "        i += step\n",
        "    return chunks\n",
        "EVIDENCE_PLAN_PROMPT = '''\n",
        "역할: 아이디어를 검증하기 위한 '질문 리스트'와 각 질문별 '검색 쿼리'를 만든다.\n",
        "출력(JSON only):\n",
        "[\n",
        "  {\"question\":\"...\", \"queries\":[\"...\",\"...\",\"...\"], \"preferred_sources\":[\"gov\",\"kosis\",\"dart\",\"research\"]},\n",
        "  ...\n",
        "]\n",
        "규칙:\n",
        "- 한국 시장/한국 기업 중심 쿼리로 작성\n",
        "- 각 question당 queries는 3개 이내\n",
        "- question은 4~6개\n",
        "'''\n",
        "evidence_plan_agent = Agent(\n",
        "    name=\"EvidencePlanMaker\",\n",
        "    instructions=EVIDENCE_PLAN_PROMPT,\n",
        "    tools=[],\n",
        ")\n",
        "\n",
        "def make_evidence_plan(idea_schema: Dict[str, Any]) -> List[Dict[str, Any]]:\n",
        "    messages = [{\"role\":\"user\",\"content\": json.dumps({\"idea_schema\": idea_schema}, ensure_ascii=False)}]\n",
        "    out = run_agent(messages, evidence_plan_agent)\n",
        "    plan = safe_json_loads(out)\n",
        "    if not isinstance(plan, list):\n",
        "        raise ValueError(\"evidence_plan must be a list\")\n",
        "    return plan\n",
        "\n",
        "def check_vectordb_cache(collection: str) -> bool:\n",
        "    try:\n",
        "        chroma_client.get_collection(name=collection)\n",
        "        return True\n",
        "    except Exception:\n",
        "        return False\n",
        "\n",
        "def build_expanded_queries(q: str) -> List[str]:\n",
        "    years = [\"2025\", \"2024\", \"2023\"]\n",
        "    tails = [\"시장 규모\", \"시장 동향 보고서\", \"통계\", \"백서\", \"TAM SAM SOM\", \"경쟁사\", \"규제\", \"지원사업\"]\n",
        "    out = []\n",
        "    for y in years:\n",
        "        out.append(f\"{q} {y}\")\n",
        "    for t in tails:\n",
        "        out.append(f\"{q} {t}\")\n",
        "    out += [f\"{q} site:go.kr\", f\"{q} site:kosis.kr\", f\"{q} DART 공시\"]\n",
        "    return list(dict.fromkeys(out))\n",
        "\n",
        "def evidence_builder_node(state: WorkflowState) -> WorkflowState:\n",
        "    logs = state.get(\"logs\", [])\n",
        "    t0 = time.time()\n",
        "\n",
        "    idea = state[\"idea_schema\"]\n",
        "    collection = f\"ideaproof_{hash_key(json.dumps(idea, ensure_ascii=False))}\"\n",
        "\n",
        "    mode = (state.get(\"request\", {}) or {}).get(\"mode\", \"standard\")\n",
        "    if mode == \"fast\":\n",
        "        MAX_RESULTS_PER_QUERY_1 = 5\n",
        "        MAX_SOURCES_1 = 12\n",
        "        MAX_CHUNKS_PER_SOURCE = 6\n",
        "        MAX_TOTAL_CHUNKS = 120\n",
        "        MIN_STORED_CHUNKS = 50\n",
        "        DO_EXPAND = False\n",
        "        DO_PDF_PARSE = False\n",
        "        TIME_BUDGET_SEC = 6 * 60\n",
        "    elif mode == \"deep\":\n",
        "        MAX_RESULTS_PER_QUERY_1 = 10\n",
        "        MAX_SOURCES_1 = 45\n",
        "        MAX_CHUNKS_PER_SOURCE = 14\n",
        "        MAX_TOTAL_CHUNKS = 450\n",
        "        MIN_STORED_CHUNKS = 180\n",
        "        DO_EXPAND = True\n",
        "        DO_PDF_PARSE = True\n",
        "        TIME_BUDGET_SEC = 18 * 60\n",
        "    else:\n",
        "        MAX_RESULTS_PER_QUERY_1 = 8\n",
        "        MAX_SOURCES_1 = 25\n",
        "        MAX_CHUNKS_PER_SOURCE = 10\n",
        "        MAX_TOTAL_CHUNKS = 260\n",
        "        MIN_STORED_CHUNKS = 120\n",
        "        DO_EXPAND = True\n",
        "        DO_PDF_PARSE = True\n",
        "        TIME_BUDGET_SEC = 12 * 60\n",
        "\n",
        "    def time_left() -> float:\n",
        "        return TIME_BUDGET_SEC - (time.time() - t0)\n",
        "\n",
        "    if check_vectordb_cache(collection):\n",
        "        state[\"evidence_store\"] = EvidenceStoreModel(collection=collection, items=[], version=\"v3\").model_dump()\n",
        "        logs.append({\"node\":\"evidence_builder\", \"t\": time.time()-t0, \"cache\":\"HIT\", \"collection\": collection, \"mode\": mode})\n",
        "        state[\"logs\"] = logs\n",
        "        return state\n",
        "\n",
        "    plan = make_evidence_plan(idea)\n",
        "    state[\"evidence_plan\"] = plan\n",
        "\n",
        "    def run_harvest(queries: List[str], max_results_per_query: int, max_sources_total: int):\n",
        "        results = []\n",
        "        for q in queries:\n",
        "            if time_left() <= 0:\n",
        "                break\n",
        "            try:\n",
        "                for r in web_search(q, k=max_results_per_query):\n",
        "                    if r.get(\"link\"):\n",
        "                        results.append(r)\n",
        "            except Exception:\n",
        "                continue\n",
        "\n",
        "        uniq = {}\n",
        "        for r in results:\n",
        "            uniq[r[\"link\"]] = r\n",
        "        ranked = list(uniq.values())\n",
        "        ranked.sort(key=lambda x: source_priority_score(x[\"link\"]), reverse=True)\n",
        "        ranked = ranked[:max_sources_total]\n",
        "\n",
        "        items: List[EvidenceItem] = []\n",
        "        all_chunks, all_metas, all_ids = [], [], []\n",
        "\n",
        "        for r in ranked:\n",
        "            if time_left() <= 0 or len(all_chunks) >= MAX_TOTAL_CHUNKS:\n",
        "                break\n",
        "\n",
        "            url = r[\"link\"]\n",
        "            title = r.get(\"title\",\"\")\n",
        "            snippet = r.get(\"snippet\",\"\")\n",
        "\n",
        "            text = \"\"\n",
        "            local = None\n",
        "            md_text = None\n",
        "\n",
        "            if is_pdf_url(url):\n",
        "                if DO_PDF_PARSE and source_priority_score(url) >= 30 and time_left() > 60:\n",
        "                    try:\n",
        "                        local = download_file(url)\n",
        "                        md_text = parse_pdf_to_markdown(local)\n",
        "                        text = (md_text or \"\").strip()\n",
        "                    except Exception:\n",
        "                        text = \"\"\n",
        "                else:\n",
        "                    text = \"\"\n",
        "            else:\n",
        "                text = fetch_url_text(url)\n",
        "\n",
        "            if not text:\n",
        "                text = f\"{title}\\n{snippet}\\nURL: {url}\"\n",
        "\n",
        "            items.append(EvidenceItem(source_url=url, title=title, snippet=snippet, local_path=local, parsed_markdown=md_text))\n",
        "\n",
        "            chunks = simple_chunk(text, max_chars=1500, overlap=200)[:MAX_CHUNKS_PER_SOURCE]\n",
        "            for j, ch in enumerate(chunks):\n",
        "                if len(all_chunks) >= MAX_TOTAL_CHUNKS:\n",
        "                    break\n",
        "                cid = hash_key(collection, url, str(j))\n",
        "                all_chunks.append(ch)\n",
        "                all_metas.append({\"url\": url, \"title\": title, \"chunk\": j})\n",
        "                all_ids.append(cid)\n",
        "\n",
        "        stored = 0\n",
        "        if all_chunks:\n",
        "            stored = vectordb_upsert(collection, all_chunks, all_metas, all_ids)\n",
        "        return items, stored\n",
        "\n",
        "    base_queries = []\n",
        "    for p in plan:\n",
        "        for q in (p.get(\"queries\") or [])[:3]:\n",
        "            base_queries.append(q)\n",
        "    base_queries = list(dict.fromkeys(base_queries))[:15]\n",
        "\n",
        "    items, stored = run_harvest(base_queries, max_results_per_query=MAX_RESULTS_PER_QUERY_1, max_sources_total=MAX_SOURCES_1)\n",
        "\n",
        "    if DO_EXPAND and (stored < MIN_STORED_CHUNKS) and (time_left() > 90):\n",
        "        expanded = []\n",
        "        for p in plan:\n",
        "            expanded += build_expanded_queries(p.get(\"question\",\"\"))\n",
        "        expanded = list(dict.fromkeys(expanded))[:20]\n",
        "\n",
        "        items2, stored2 = run_harvest(expanded, max_results_per_query=MAX_RESULTS_PER_QUERY_1, max_sources_total=max(MAX_SOURCES_1, 30))\n",
        "        merged = {it.source_url: it for it in (items + items2)}\n",
        "        items = list(merged.values())\n",
        "        stored = max(stored, stored2)\n",
        "\n",
        "    state[\"evidence_store\"] = EvidenceStoreModel(collection=collection, items=items, version=\"v3\").model_dump()\n",
        "\n",
        "    logs.append({\n",
        "        \"node\":\"evidence_builder\",\n",
        "        \"t\": time.time()-t0,\n",
        "        \"cache\":\"MISS\",\n",
        "        \"collection\": collection,\n",
        "        \"mode\": mode,\n",
        "        \"sources\": len(items),\n",
        "        \"stored_chunks\": stored,\n",
        "        \"time_budget_sec\": TIME_BUDGET_SEC,\n",
        "        \"time_budget_hit\": (time_left() <= 0)\n",
        "    })\n",
        "    state[\"logs\"] = logs\n",
        "    return state\n"
      ],
      "metadata": {
        "id": "mhQun7fkBMLx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4) State Models (Design Doc)\n",
        "\n",
        "설계서의 상태(State) 모델을 그대로 반영합니다:\n",
        "- request, idea_schema, evidence_plan, evidence_store, signals, verdict, artifacts, guards\n"
      ],
      "metadata": {
        "id": "quIIb_MOaKW5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RequestModel(BaseModel):\n",
        "    raw_request: str\n",
        "    language: str = \"ko\"\n",
        "    tone: str = \"concise\"\n",
        "    mode: Literal[\"fast\",\"standard\",\"deep\"] = \"standard\"\n",
        "\n",
        "class IdeaSchemaModel(BaseModel):\n",
        "    problem: str\n",
        "    target: str\n",
        "    solution: str\n",
        "    differentiation: str\n",
        "    business_model: str\n",
        "    industry: str\n",
        "    keywords: List[str] = Field(default_factory=list)\n",
        "    persona_hypotheses: List[str] = Field(default_factory=list)\n",
        "\n",
        "class EvidenceQueryPlan(BaseModel):\n",
        "    question: str\n",
        "    queries: List[str]\n",
        "    preferred_sources: List[str] = Field(default_factory=list)\n",
        "\n",
        "class EvidenceItem(BaseModel):\n",
        "    source_url: str\n",
        "    title: str = \"\"\n",
        "    snippet: str = \"\"\n",
        "    local_path: Optional[str] = None\n",
        "    parsed_markdown: Optional[str] = None\n",
        "\n",
        "class EvidenceStoreModel(BaseModel):\n",
        "    collection: str\n",
        "    items: List[EvidenceItem] = Field(default_factory=list)\n",
        "    version: str = \"v1\"\n",
        "\n",
        "class SignalsModel(BaseModel):\n",
        "    market: str\n",
        "    competition: str\n",
        "    customer: str\n",
        "    risks: str\n",
        "    score_explainable: Dict[str, float]\n",
        "\n",
        "class VerdictModel(BaseModel):\n",
        "    decision: Literal[\"GO\",\"NO_GO\",\"PIVOT\"]\n",
        "    key_reasons: List[str]\n",
        "    evidence_links: List[str]\n",
        "    next_actions: List[str]\n",
        "\n",
        "class ArtifactsModel(BaseModel):\n",
        "    prd_1p: str\n",
        "    scope_must_should_could: str\n",
        "    erd_mermaid: str\n",
        "    user_flow: str\n",
        "    roadmap_2_4_weeks: str\n",
        "    validation_plan: str\n",
        "\n",
        "class GuardsModel(BaseModel):\n",
        "    policy_violation: bool = False\n",
        "    token_overflow: bool = False\n",
        "    copyright_risk: bool = False\n",
        "    evidence_insufficient: bool = False\n",
        "    notes: List[str] = Field(default_factory=list)\n",
        "\n",
        "class WorkflowState(TypedDict, total=False):\n",
        "    request: Dict[str, Any]\n",
        "    idea_schema: Dict[str, Any]\n",
        "    evidence_plan: List[Dict[str, Any]]\n",
        "    evidence_store: Dict[str, Any]\n",
        "    evidence_pack: List[Dict[str, Any]]\n",
        "    signals: Dict[str, Any]\n",
        "    verdict: Dict[str, Any]\n",
        "    artifacts: Dict[str, Any]\n",
        "    guards: Dict[str, Any]\n",
        "    final_report_markdown: str\n",
        "    intake: Dict[str, Any]\n",
        "    logs: List[Dict[str, Any]]\n"
      ],
      "metadata": {
        "id": "BCVMGf7yBOpV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5) Agent Base (Vanilla tool-calling loop)\n"
      ],
      "metadata": {
        "id": "DOzDrBVzaOO3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Agent(BaseModel):\n",
        "    name: str = \"Agent\"\n",
        "    model: str = \"solar-pro2-250909\"\n",
        "    instructions: str = \"You are a helpful agent.\"\n",
        "    tools: List[Any] = Field(default_factory=list)\n",
        "\n",
        "def run_agent(messages: List[Dict[str, Any]], agent: Agent, max_context_limit: int = None) -> str:\n",
        "    \"\"\"\n",
        "    OpenAI tool-calling 스타일 루프 실행.\n",
        "    - tools가 없으면 tools/tool_choice 파라미터를 아예 보내지 않는다(Upstage 400 방지)\n",
        "    \"\"\"\n",
        "    if max_context_limit is None:\n",
        "        max_context_limit = MAX_CONTEXT_LIMIT\n",
        "\n",
        "    tool_schemas = [function_to_schema(t) for t in agent.tools]\n",
        "    tool_map = {t.__name__: t for t in agent.tools}\n",
        "\n",
        "    while True:\n",
        "        kwargs = dict(\n",
        "            model=agent.model,\n",
        "            messages=[{\"role\":\"system\",\"content\": agent.instructions}] + messages,\n",
        "        )\n",
        "        if tool_schemas:\n",
        "            kwargs[\"tools\"] = tool_schemas\n",
        "            kwargs[\"tool_choice\"] = \"auto\"\n",
        "\n",
        "        resp = client.chat.completions.create(**kwargs)\n",
        "        msg = resp.choices[0].message\n",
        "\n",
        "        if not getattr(msg, \"tool_calls\", None):\n",
        "            content = msg.content or \"\"\n",
        "            content = truncate_tokens_if_needed(tokenizer, agent.instructions, messages, content, max_token_limit=max_context_limit)\n",
        "            return content\n",
        "\n",
        "        for tc in msg.tool_calls:\n",
        "            tool_name = tc.function.name\n",
        "            args = json.loads(tc.function.arguments or \"{}\")\n",
        "            try:\n",
        "                out = execute_tool_call(tool_name, tool_map, args)\n",
        "                if not isinstance(out, str):\n",
        "                    out = json.dumps(out, ensure_ascii=False)\n",
        "            except Exception as e:\n",
        "                out = f\"ToolError: {e}\"\n",
        "\n",
        "            out = truncate_tokens_if_needed(tokenizer, agent.instructions, messages, out, max_token_limit=max_context_limit)\n",
        "\n",
        "            messages.append({\"role\":\"assistant\",\"content\": None, \"tool_calls\":[tc]})\n",
        "            messages.append({\"role\":\"tool\",\"tool_call_id\": tc.id, \"content\": out})\n"
      ],
      "metadata": {
        "id": "XMfpP0JuBPxz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6) Agents (per design nodes)\n"
      ],
      "metadata": {
        "id": "Cx90c79aaRhj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6-1) Intake Route Clarify Agent\n"
      ],
      "metadata": {
        "id": "OiQ5l_lgaSDF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "INTAKE_PROMPT = \"\"\"\n",
        "역할: 요청을 '아이디어 검증/설계 워크플로'로 처리할지, 일상대화로 처리할지 라우팅한다.\n",
        "목표:\n",
        "1) request 정규화(언어/톤/모드)\n",
        "2) 아이디어 입력이 부족하면 '최소 질문'으로 보완 질문을 만든다.\n",
        "출력(JSON only):\n",
        "{\n",
        "  \"route\": \"workflow\" | \"chat\",\n",
        "  \"request\": {\"raw_request\": \"...\", \"language\": \"ko\", \"tone\": \"concise\", \"mode\":\"fast|standard|deep\"},\n",
        "  \"missing_fields\": [\"problem\",\"target\",\"solution\",\"differentiation\",\"business_model\"],\n",
        "  \"clarifying_questions\": [\"...\",\"...\"]\n",
        "}\n",
        "규칙:\n",
        "- 질문은 최대 5개. 선택형/단답형 우선.\n",
        "\"\"\"\n",
        "\n",
        "intake_agent = Agent(name=\"IntakeRouteClarify\", instructions=INTAKE_PROMPT, tools=[])\n",
        "\n",
        "def intake_node(state: WorkflowState) -> WorkflowState:\n",
        "    logs = state.get(\"logs\", [])\n",
        "    t0 = time.time()\n",
        "\n",
        "    raw = state[\"request\"][\"raw_request\"]\n",
        "    messages = [{\"role\":\"user\",\"content\": raw}]\n",
        "    out = run_agent(messages, intake_agent)\n",
        "    data = safe_json_loads(out)\n",
        "\n",
        "    state[\"request\"] = data[\"request\"]\n",
        "    state[\"intake\"] = data\n",
        "\n",
        "    guards = state.get(\"guards\", {})\n",
        "    guards.setdefault(\"notes\", [])\n",
        "    guards[\"notes\"].append(f\"route={data.get('route')}\")\n",
        "    state[\"guards\"] = guards\n",
        "\n",
        "    logs.append({\"node\":\"intake\", \"t\": time.time()-t0, \"route\": data.get(\"route\")})\n",
        "    state[\"logs\"] = logs\n",
        "    return state\n",
        "\n",
        "def route_after_intake(state: WorkflowState) -> str:\n",
        "    route = state.get(\"intake\", {}).get(\"route\", \"workflow\")\n",
        "    return \"chat_end\" if route == \"chat\" else \"structurer\"\n"
      ],
      "metadata": {
        "id": "0yZxbR7WBR1w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6-2) Structurer Agent\n"
      ],
      "metadata": {
        "id": "fS5GId7vaVi4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "STRUCTURER_PROMPT = \"\"\"\n",
        "역할: 아이디어를 문제/대상/해결/차별/BM로 구조화하고, 산업 분류 및 키워드를 만든다.\n",
        "입력:\n",
        "- raw idea text(자유형)\n",
        "출력(JSON only):\n",
        "{\n",
        "  \"problem\": \"...\",\n",
        "  \"target\": \"...\",\n",
        "  \"solution\": \"...\",\n",
        "  \"differentiation\": \"...\",\n",
        "  \"business_model\": \"...\",\n",
        "  \"industry\": \"...\",\n",
        "  \"keywords\": [\"...\"],\n",
        "  \"persona_hypotheses\": [\"...\"]\n",
        "}\n",
        "규칙:\n",
        "- 모호하면 가능한 가설을 1~2개로 제한해 persona_hypotheses에 넣고, 단정하지 말 것.\n",
        "\"\"\"\n",
        "\n",
        "structurer_agent = Agent(name=\"Structurer\", instructions=STRUCTURER_PROMPT, tools=[])\n",
        "\n",
        "def structurer_node(state: WorkflowState) -> WorkflowState:\n",
        "    logs = state.get(\"logs\", [])\n",
        "    t0 = time.time()\n",
        "\n",
        "    raw = state[\"request\"][\"raw_request\"]\n",
        "    messages = [{\"role\":\"user\",\"content\": raw}]\n",
        "    out = run_agent(messages, structurer_agent)\n",
        "    data = safe_json_loads(out)\n",
        "\n",
        "    obj = IdeaSchemaModel(**data)\n",
        "    state[\"idea_schema\"] = obj.model_dump()\n",
        "\n",
        "    logs.append({\"node\":\"structurer\", \"t\": time.time()-t0, \"industry\": obj.industry})\n",
        "    state[\"logs\"] = logs\n",
        "    return state\n"
      ],
      "metadata": {
        "id": "xJk0TYlOBVIz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6-3) Evidence Builder Agent (cache + web search + optional pdf parse + vectordb upsert)\n"
      ],
      "metadata": {
        "id": "YyJUKI5WaZGq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EVIDENCE_PLAN_PROMPT = '''\n",
        "역할: 아이디어를 검증하기 위한 '질문 리스트'와 각 질문별 '검색 쿼리'를 만든다.\n",
        "출력(JSON only):\n",
        "[\n",
        "  {\"question\":\"...\", \"queries\":[\"...\",\"...\",\"...\"], \"preferred_sources\":[\"gov\",\"kosis\",\"dart\",\"research\"]},\n",
        "  ...\n",
        "]\n",
        "규칙:\n",
        "- 한국 시장/한국 기업 중심 쿼리로 작성\n",
        "- 각 question당 queries는 3개 이내\n",
        "- question은 4~6개\n",
        "'''\n",
        "evidence_plan_agent = Agent(\n",
        "    name=\"EvidencePlanMaker\",\n",
        "    instructions=EVIDENCE_PLAN_PROMPT,\n",
        "    tools=[],\n",
        ")\n",
        "\n",
        "def make_evidence_plan(idea_schema: Dict[str, Any]) -> List[Dict[str, Any]]:\n",
        "    messages = [{\"role\":\"user\",\"content\": json.dumps({\"idea_schema\": idea_schema}, ensure_ascii=False)}]\n",
        "    out = run_agent(messages, evidence_plan_agent)\n",
        "    plan = safe_json_loads(out)\n",
        "    if not isinstance(plan, list):\n",
        "        raise ValueError(\"evidence_plan must be a list\")\n",
        "    return plan\n",
        "\n",
        "def check_vectordb_cache(collection: str) -> bool:\n",
        "    try:\n",
        "        chroma_client.get_collection(name=collection)\n",
        "        return True\n",
        "    except Exception:\n",
        "        return False\n",
        "\n",
        "def build_expanded_queries(q: str) -> List[str]:\n",
        "    years = [\"2025\", \"2024\", \"2023\"]\n",
        "    tails = [\"시장 규모\", \"시장 동향 보고서\", \"통계\", \"백서\", \"TAM SAM SOM\", \"경쟁사\", \"규제\", \"지원사업\"]\n",
        "    out = []\n",
        "    for y in years:\n",
        "        out.append(f\"{q} {y}\")\n",
        "    for t in tails:\n",
        "        out.append(f\"{q} {t}\")\n",
        "    out += [f\"{q} site:go.kr\", f\"{q} site:kosis.kr\", f\"{q} DART 공시\"]\n",
        "    return list(dict.fromkeys(out))\n",
        "\n",
        "def evidence_builder_node(state: WorkflowState) -> WorkflowState:\n",
        "    logs = state.get(\"logs\", [])\n",
        "    t0 = time.time()\n",
        "\n",
        "    idea = state[\"idea_schema\"]\n",
        "    collection = f\"ideaproof_{hash_key(json.dumps(idea, ensure_ascii=False))}\"\n",
        "\n",
        "    mode = (state.get(\"request\", {}) or {}).get(\"mode\", \"standard\")\n",
        "    if mode == \"fast\":\n",
        "        MAX_RESULTS_PER_QUERY_1 = 5\n",
        "        MAX_SOURCES_1 = 12\n",
        "        MAX_CHUNKS_PER_SOURCE = 6\n",
        "        MAX_TOTAL_CHUNKS = 120\n",
        "        MIN_STORED_CHUNKS = 50\n",
        "        DO_EXPAND = False\n",
        "        DO_PDF_PARSE = False\n",
        "        TIME_BUDGET_SEC = 6 * 60\n",
        "    elif mode == \"deep\":\n",
        "        MAX_RESULTS_PER_QUERY_1 = 10\n",
        "        MAX_SOURCES_1 = 45\n",
        "        MAX_CHUNKS_PER_SOURCE = 14\n",
        "        MAX_TOTAL_CHUNKS = 450\n",
        "        MIN_STORED_CHUNKS = 180\n",
        "        DO_EXPAND = True\n",
        "        DO_PDF_PARSE = True\n",
        "        TIME_BUDGET_SEC = 18 * 60\n",
        "    else:\n",
        "        MAX_RESULTS_PER_QUERY_1 = 8\n",
        "        MAX_SOURCES_1 = 25\n",
        "        MAX_CHUNKS_PER_SOURCE = 10\n",
        "        MAX_TOTAL_CHUNKS = 260\n",
        "        MIN_STORED_CHUNKS = 120\n",
        "        DO_EXPAND = True\n",
        "        DO_PDF_PARSE = True\n",
        "        TIME_BUDGET_SEC = 12 * 60\n",
        "\n",
        "    def time_left() -> float:\n",
        "        return TIME_BUDGET_SEC - (time.time() - t0)\n",
        "\n",
        "    if check_vectordb_cache(collection):\n",
        "        state[\"evidence_store\"] = EvidenceStoreModel(collection=collection, items=[], version=\"v3\").model_dump()\n",
        "        logs.append({\"node\":\"evidence_builder\", \"t\": time.time()-t0, \"cache\":\"HIT\", \"collection\": collection, \"mode\": mode})\n",
        "        state[\"logs\"] = logs\n",
        "        return state\n",
        "\n",
        "    plan = make_evidence_plan(idea)\n",
        "    state[\"evidence_plan\"] = plan\n",
        "\n",
        "    def run_harvest(queries: List[str], max_results_per_query: int, max_sources_total: int):\n",
        "        results = []\n",
        "        for q in queries:\n",
        "            if time_left() <= 0:\n",
        "                break\n",
        "            try:\n",
        "                for r in web_search(q, k=max_results_per_query):\n",
        "                    if r.get(\"link\"):\n",
        "                        results.append(r)\n",
        "            except Exception:\n",
        "                continue\n",
        "\n",
        "        uniq = {}\n",
        "        for r in results:\n",
        "            uniq[r[\"link\"]] = r\n",
        "        ranked = list(uniq.values())\n",
        "        ranked.sort(key=lambda x: source_priority_score(x[\"link\"]), reverse=True)\n",
        "        ranked = ranked[:max_sources_total]\n",
        "\n",
        "        items: List[EvidenceItem] = []\n",
        "        all_chunks, all_metas, all_ids = [], [], []\n",
        "\n",
        "        for r in ranked:\n",
        "            if time_left() <= 0 or len(all_chunks) >= MAX_TOTAL_CHUNKS:\n",
        "                break\n",
        "\n",
        "            url = r[\"link\"]\n",
        "            title = r.get(\"title\",\"\")\n",
        "            snippet = r.get(\"snippet\",\"\")\n",
        "\n",
        "            text = \"\"\n",
        "            local = None\n",
        "            md_text = None\n",
        "\n",
        "            if is_pdf_url(url):\n",
        "                if DO_PDF_PARSE and source_priority_score(url) >= 30 and time_left() > 60:\n",
        "                    try:\n",
        "                        local = download_file(url)\n",
        "                        md_text = parse_pdf_to_markdown(local)\n",
        "                        text = (md_text or \"\").strip()\n",
        "                    except Exception:\n",
        "                        text = \"\"\n",
        "                else:\n",
        "                    text = \"\"\n",
        "            else:\n",
        "                text = fetch_url_text(url)\n",
        "\n",
        "            if not text:\n",
        "                text = f\"{title}\\n{snippet}\\nURL: {url}\"\n",
        "\n",
        "            items.append(EvidenceItem(source_url=url, title=title, snippet=snippet, local_path=local, parsed_markdown=md_text))\n",
        "\n",
        "            chunks = simple_chunk(text, max_chars=1500, overlap=200)[:MAX_CHUNKS_PER_SOURCE]\n",
        "            for j, ch in enumerate(chunks):\n",
        "                if len(all_chunks) >= MAX_TOTAL_CHUNKS:\n",
        "                    break\n",
        "                cid = hash_key(collection, url, str(j))\n",
        "                all_chunks.append(ch)\n",
        "                all_metas.append({\"url\": url, \"title\": title, \"chunk\": j})\n",
        "                all_ids.append(cid)\n",
        "\n",
        "        stored = 0\n",
        "        if all_chunks:\n",
        "            stored = vectordb_upsert(collection, all_chunks, all_metas, all_ids)\n",
        "        return items, stored\n",
        "\n",
        "    base_queries = []\n",
        "    for p in plan:\n",
        "        for q in (p.get(\"queries\") or [])[:3]:\n",
        "            base_queries.append(q)\n",
        "    base_queries = list(dict.fromkeys(base_queries))[:15]\n",
        "\n",
        "    items, stored = run_harvest(base_queries, max_results_per_query=MAX_RESULTS_PER_QUERY_1, max_sources_total=MAX_SOURCES_1)\n",
        "\n",
        "    if DO_EXPAND and (stored < MIN_STORED_CHUNKS) and (time_left() > 90):\n",
        "        expanded = []\n",
        "        for p in plan:\n",
        "            expanded += build_expanded_queries(p.get(\"question\",\"\"))\n",
        "        expanded = list(dict.fromkeys(expanded))[:20]\n",
        "\n",
        "        items2, stored2 = run_harvest(expanded, max_results_per_query=MAX_RESULTS_PER_QUERY_1, max_sources_total=max(MAX_SOURCES_1, 30))\n",
        "        merged = {it.source_url: it for it in (items + items2)}\n",
        "        items = list(merged.values())\n",
        "        stored = max(stored, stored2)\n",
        "\n",
        "    state[\"evidence_store\"] = EvidenceStoreModel(collection=collection, items=items, version=\"v3\").model_dump()\n",
        "\n",
        "    logs.append({\n",
        "        \"node\":\"evidence_builder\",\n",
        "        \"t\": time.time()-t0,\n",
        "        \"cache\":\"MISS\",\n",
        "        \"collection\": collection,\n",
        "        \"mode\": mode,\n",
        "        \"sources\": len(items),\n",
        "        \"stored_chunks\": stored,\n",
        "        \"time_budget_sec\": TIME_BUDGET_SEC,\n",
        "        \"time_budget_hit\": (time_left() <= 0)\n",
        "    })\n",
        "    state[\"logs\"] = logs\n",
        "    return state\n"
      ],
      "metadata": {
        "id": "b9usg07vBXjP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6-4) Extractor Agent (VectorDB retrieve + LLM rerank)\n"
      ],
      "metadata": {
        "id": "V_jl61fracQ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extractor_node(state: WorkflowState) -> WorkflowState:\n",
        "    logs = state.get(\"logs\", [])\n",
        "    t0 = time.time()\n",
        "\n",
        "    plan = state.get(\"evidence_plan\", [])\n",
        "    collection = state[\"evidence_store\"][\"collection\"]\n",
        "\n",
        "    evidence_pack = []\n",
        "    for p in plan[:6]:\n",
        "        q = p.get(\"question\",\"\")\n",
        "        if not q:\n",
        "            continue\n",
        "\n",
        "        raw = vectordb_query(collection=collection, query=q, n_results=12)\n",
        "        docs = raw.get(\"documents\", [[]])[0]\n",
        "        metas = raw.get(\"metadatas\", [[]])[0]\n",
        "\n",
        "        if not docs:\n",
        "            continue\n",
        "\n",
        "        candidates = [{\"text\": d, \"meta\": m} for d, m in zip(docs, metas)]\n",
        "        reranked = llm_rerank(query=q, candidates=candidates, top_k=5)\n",
        "\n",
        "        for r in reranked:\n",
        "            r[\"text\"] = (r.get(\"text\",\"\")[:800]).strip()\n",
        "\n",
        "        evidence_pack.append({\"question\": q, \"top_chunks\": reranked})\n",
        "\n",
        "    state[\"evidence_pack\"] = evidence_pack\n",
        "\n",
        "    guards = state.get(\"guards\", {})\n",
        "    if not evidence_pack:\n",
        "        guards[\"evidence_insufficient\"] = True\n",
        "        guards.setdefault(\"notes\", []).append(\"Extractor: evidence_pack is empty.\")\n",
        "    state[\"guards\"] = guards\n",
        "\n",
        "    logs.append({\"node\":\"extractor\", \"t\": time.time()-t0, \"questions\": len(evidence_pack)})\n",
        "    state[\"logs\"] = logs\n",
        "    return state\n"
      ],
      "metadata": {
        "id": "sw8L29NbBZdM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6-5) Analysis Agent (signals + explainable scoring)\n"
      ],
      "metadata": {
        "id": "wRlp65-0alR7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ANALYSIS_PROMPT = \"\"\"\n",
        "역할: evidence_pack을 기반으로 시장/경쟁/고객/리스크 신호를 요약하고,\n",
        "설명가능한 점수(0~5)를 만든다.\n",
        "출력(JSON only):\n",
        "{\n",
        "  \"market\": \"...\",\n",
        "  \"competition\": \"...\",\n",
        "  \"customer\": \"...\",\n",
        "  \"risks\": \"...\",\n",
        "  \"score_explainable\": {\"market\":3.0,\"competition\":2.5,\"customer\":3.5,\"risks\":2.0}\n",
        "}\n",
        "규칙:\n",
        "- fact / interpretation / hypothesis를 문장 앞 라벨로 구분해라.\n",
        "- 수치(성장률 등)는 evidence_pack에 근거가 없으면 생성하지 마라.\n",
        "\"\"\"\n",
        "\n",
        "analysis_agent = Agent(name=\"Analysis\", instructions=ANALYSIS_PROMPT, tools=[])\n",
        "\n",
        "def analysis_node(state: WorkflowState) -> WorkflowState:\n",
        "    logs = state.get(\"logs\", [])\n",
        "    t0 = time.time()\n",
        "\n",
        "    payload = {\n",
        "        \"idea_schema\": state[\"idea_schema\"],\n",
        "        \"evidence_pack\": state.get(\"evidence_pack\", [])\n",
        "    }\n",
        "    messages = [{\"role\":\"user\",\"content\": json.dumps(payload, ensure_ascii=False)}]\n",
        "    out = run_agent(messages, analysis_agent)\n",
        "    data = safe_json_loads(out)\n",
        "\n",
        "    obj = SignalsModel(**data)\n",
        "    state[\"signals\"] = obj.model_dump()\n",
        "\n",
        "    logs.append({\"node\":\"analysis\", \"t\": time.time()-t0, \"score\": obj.score_explainable})\n",
        "    state[\"logs\"] = logs\n",
        "    return state\n"
      ],
      "metadata": {
        "id": "BnPb64wKBbH8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6-6) Decision Agent\n"
      ],
      "metadata": {
        "id": "OZtgKDEuaoTh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DECISION_PROMPT = \"\"\"\n",
        "역할: signals + evidence_pack을 바탕으로\n",
        "GO / NO_GO / PIVOT 결론을 내리고, 근거 링크와 다음 액션(검증 실험 포함)을 제안한다.\n",
        "출력(JSON only):\n",
        "{\n",
        "  \"decision\":\"GO|NO_GO|PIVOT\",\n",
        "  \"key_reasons\":[\"...\"],\n",
        "  \"evidence_links\":[\"...\"],\n",
        "  \"next_actions\":[\"...\"]\n",
        "}\n",
        "규칙:\n",
        "- evidence_links는 evidence_pack.meta.url에서만 가져와라(최소 3개).\n",
        "- 단정 금지: 불확실하면 PIVOT 또는 조건부 GO로 표현.\n",
        "\"\"\"\n",
        "\n",
        "decision_agent = Agent(name=\"Decision\", instructions=DECISION_PROMPT, tools=[])\n",
        "\n",
        "def decision_node(state: WorkflowState) -> WorkflowState:\n",
        "    logs = state.get(\"logs\", [])\n",
        "    t0 = time.time()\n",
        "\n",
        "    payload = {\n",
        "        \"idea_schema\": state[\"idea_schema\"],\n",
        "        \"signals\": state.get(\"signals\", {}),\n",
        "        \"evidence_pack\": state.get(\"evidence_pack\", [])\n",
        "    }\n",
        "    messages = [{\"role\":\"user\",\"content\": json.dumps(payload, ensure_ascii=False)}]\n",
        "    out = run_agent(messages, decision_agent)\n",
        "    data = safe_json_loads(out)\n",
        "\n",
        "    obj = VerdictModel(**data)\n",
        "    state[\"verdict\"] = obj.model_dump()\n",
        "\n",
        "    logs.append({\"node\":\"decision\", \"t\": time.time()-t0, \"decision\": obj.decision})\n",
        "    state[\"logs\"] = logs\n",
        "    return state\n",
        "\n",
        "def route_after_decision(state: WorkflowState) -> str:\n",
        "    return \"blueprint\"\n"
      ],
      "metadata": {
        "id": "guIzrL9JBc3G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6-7) Blueprint Agent\n"
      ],
      "metadata": {
        "id": "sNMsXp5kaq_q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BLUEPRINT_PROMPT = '''\n",
        "역할: verdict를 반영하여 MVP 설계 산출물을 만든다.\n",
        "출력(JSON only):\n",
        "{\n",
        "  \"prd_1p\": \"<markdown string>\",\n",
        "  \"scope_must_should_could\": \"<markdown string>\",\n",
        "  \"erd_mermaid\": \"```mermaid ...```\",\n",
        "  \"user_flow\": \"<markdown string>\",\n",
        "  \"roadmap_2_4_weeks\": \"<markdown string>\",\n",
        "  \"validation_plan\": \"<markdown string>\"\n",
        "}\n",
        "규칙:\n",
        "- 위 6개 필드는 '문자열'이어야 한다. (객체/리스트 JSON으로 내지 말 것)\n",
        "- scope/roadmap/validation은 사람이 읽기 좋은 bullet markdown으로 작성.\n",
        "- ERD는 Mermaid ER diagram 또는 flowchart 형식.\n",
        "- 검증 플랜은 '실험-지표-판정기준'이 포함되어야 함.\n",
        "'''\n",
        "blueprint_agent = Agent(\n",
        "    name=\"BlueprintMaker\",\n",
        "    instructions=BLUEPRINT_PROMPT,\n",
        "    tools=[],\n",
        ")\n",
        "\n",
        "def _to_markdown(x: Any, indent: int = 0) -> str:\n",
        "    pad = \"  \" * indent\n",
        "    if x is None:\n",
        "        return \"\"\n",
        "    if isinstance(x, str):\n",
        "        return x.strip()\n",
        "    if isinstance(x, list):\n",
        "        lines = []\n",
        "        for item in x:\n",
        "            if isinstance(item, (dict, list)):\n",
        "                lines.append(f\"{pad}-\")\n",
        "                child = _to_markdown(item, indent+1)\n",
        "                if child:\n",
        "                    lines.append(child)\n",
        "            else:\n",
        "                lines.append(f\"{pad}- {str(item)}\")\n",
        "        return \"\\n\".join(lines).strip()\n",
        "    if isinstance(x, dict):\n",
        "        lines = []\n",
        "        for k, v in x.items():\n",
        "            if isinstance(v, (dict, list)):\n",
        "                lines.append(f\"{pad}- **{k}**\")\n",
        "                child = _to_markdown(v, indent+1)\n",
        "                if child:\n",
        "                    lines.append(child)\n",
        "            else:\n",
        "                lines.append(f\"{pad}- **{k}**: {str(v)}\")\n",
        "        return \"\\n\".join(lines).strip()\n",
        "    return str(x).strip()\n",
        "\n",
        "def blueprint_node(state: WorkflowState) -> WorkflowState:\n",
        "    logs = state.get(\"logs\", [])\n",
        "    t0 = time.time()\n",
        "\n",
        "    payload = {\n",
        "        \"idea_schema\": state[\"idea_schema\"],\n",
        "        \"signals\": state.get(\"signals\", {}),\n",
        "        \"verdict\": state.get(\"verdict\", {})\n",
        "    }\n",
        "    messages = [{\"role\":\"user\",\"content\": json.dumps(payload, ensure_ascii=False)}]\n",
        "    out = run_agent(messages, blueprint_agent)\n",
        "    data = safe_json_loads(out)\n",
        "\n",
        "    for key in [\"prd_1p\", \"scope_must_should_could\", \"erd_mermaid\", \"user_flow\", \"roadmap_2_4_weeks\", \"validation_plan\"]:\n",
        "        if key in data and not isinstance(data[key], str):\n",
        "            data[key] = _to_markdown(data[key])\n",
        "\n",
        "    obj = ArtifactsModel(**data)\n",
        "    state[\"artifacts\"] = obj.model_dump()\n",
        "\n",
        "    logs.append({\"node\":\"blueprint\", \"t\": time.time()-t0})\n",
        "    state[\"logs\"] = logs\n",
        "    return state\n"
      ],
      "metadata": {
        "id": "r8t02YG8Bfgw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6-8) Guardrail / Validator Agent\n"
      ],
      "metadata": {
        "id": "jlOk9N61atmp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "GUARDRAIL_PROMPT = \"\"\"\n",
        "역할: 최종 산출물(analysis/verdict/artifacts)이 아래 가드를 충족하는지 점검하고,\n",
        "위반/부족 플래그를 설정하며, 필요한 최소 수정(라벨/단정 표현 완화/링크 누락 보완)을 제안한다.\n",
        "출력(JSON only):\n",
        "{\n",
        "  \"policy_violation\": false,\n",
        "  \"token_overflow\": false,\n",
        "  \"copyright_risk\": false,\n",
        "  \"evidence_insufficient\": false,\n",
        "  \"notes\": [\"...\"]\n",
        "}\n",
        "체크리스트:\n",
        "- 핵심 주장에 출처 링크가 최소 3개 이상인가?\n",
        "- fact/interpretation/hypothesis 라벨이 존재하는가?\n",
        "- 수치가 '근거 없이' 생성되지 않았는가?\n",
        "- 뉴스/리포트 전문을 길게 인용하지 않았는가?\n",
        "\"\"\"\n",
        "\n",
        "guardrail_agent = Agent(name=\"GuardrailValidator\", instructions=GUARDRAIL_PROMPT, tools=[])\n",
        "\n",
        "def guardrail_node(state: WorkflowState) -> WorkflowState:\n",
        "    logs = state.get(\"logs\", [])\n",
        "    t0 = time.time()\n",
        "\n",
        "    payload = {\n",
        "        \"signals\": state.get(\"signals\", {}),\n",
        "        \"verdict\": state.get(\"verdict\", {}),\n",
        "        \"artifacts\": state.get(\"artifacts\", {}),\n",
        "        \"evidence_pack\": state.get(\"evidence_pack\", [])\n",
        "    }\n",
        "    messages = [{\"role\":\"user\",\"content\": json.dumps(payload, ensure_ascii=False)}]\n",
        "    out = run_agent(messages, guardrail_agent)\n",
        "    data = safe_json_loads(out)\n",
        "\n",
        "    obj = GuardsModel(**data)\n",
        "    state[\"guards\"] = obj.model_dump()\n",
        "\n",
        "    logs.append({\"node\":\"guardrail\", \"t\": time.time()-t0, \"flags\": {\n",
        "        \"policy_violation\": obj.policy_violation,\n",
        "        \"token_overflow\": obj.token_overflow,\n",
        "        \"copyright_risk\": obj.copyright_risk,\n",
        "        \"evidence_insufficient\": obj.evidence_insufficient\n",
        "    }})\n",
        "    state[\"logs\"] = logs\n",
        "    return state\n"
      ],
      "metadata": {
        "id": "ovwuMtmdBhWE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6-9) Render Agent\n"
      ],
      "metadata": {
        "id": "rCTURKBKawGP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def render_report(state: WorkflowState) -> str:\n",
        "    idea = state.get(\"idea_schema\", {})\n",
        "    signals = state.get(\"signals\", {})\n",
        "    verdict = state.get(\"verdict\", {})\n",
        "    artifacts = state.get(\"artifacts\", {})\n",
        "    guards = state.get(\"guards\", {})\n",
        "    evidence_pack = state.get(\"evidence_pack\", [])\n",
        "\n",
        "    links = []\n",
        "    for ep in evidence_pack:\n",
        "        for ch in ep.get(\"top_chunks\", []):\n",
        "            url = (ch.get(\"meta\") or {}).get(\"url\")\n",
        "            if url:\n",
        "                links.append(url)\n",
        "    links = list(dict.fromkeys(links))[:10]\n",
        "\n",
        "    out = []\n",
        "    out.append(\"# IdeaProof 결과 리포트 (Prototype)\\n\")\n",
        "    out.append(\"## 1) 아이디어 구조화\\n\")\n",
        "    out.append(f\"- 문제: {idea.get('problem','')}\\n- 대상: {idea.get('target','')}\\n- 해결: {idea.get('solution','')}\\n- 차별: {idea.get('differentiation','')}\\n- BM: {idea.get('business_model','')}\\n- 산업: {idea.get('industry','')}\\n- 키워드: {', '.join(idea.get('keywords',[]))}\\n\")\n",
        "\n",
        "    out.append(\"\\n## 2) 신호(시장/경쟁/고객/리스크)\\n\")\n",
        "    out.append(f\"### Market\\n{signals.get('market','')}\\n\\n### Competition\\n{signals.get('competition','')}\\n\\n### Customer\\n{signals.get('customer','')}\\n\\n### Risks\\n{signals.get('risks','')}\\n\")\n",
        "    out.append(f\"\\n**Explainable Score(0~5):** {json.dumps(signals.get('score_explainable',{}), ensure_ascii=False)}\\n\")\n",
        "\n",
        "    out.append(\"\\n## 3) 결론\\n\")\n",
        "    out.append(f\"**Decision:** {verdict.get('decision','')}\\n\\n\")\n",
        "    out.append(\"**Key reasons**\\n\" + \"\\n\".join([f\"- {x}\" for x in verdict.get(\"key_reasons\",[])]) + \"\\n\")\n",
        "    out.append(\"\\n**Next actions**\\n\" + \"\\n\".join([f\"- {x}\" for x in verdict.get(\"next_actions\",[])]) + \"\\n\")\n",
        "\n",
        "    out.append(\"\\n## 4) MVP 설계 산출물\\n\")\n",
        "    out.append(\"### PRD 1p\\n\" + artifacts.get(\"prd_1p\",\"\") + \"\\n\")\n",
        "    out.append(\"\\n### Scope (Must / Should / Could)\\n\" + artifacts.get(\"scope_must_should_could\",\"\") + \"\\n\")\n",
        "    out.append(\"\\n### ERD (Mermaid)\\n\" + artifacts.get(\"erd_mermaid\",\"\") + \"\\n\")\n",
        "    out.append(\"\\n### User Flow\\n\" + artifacts.get(\"user_flow\",\"\") + \"\\n\")\n",
        "    out.append(\"\\n### Roadmap (2~4 weeks)\\n\" + artifacts.get(\"roadmap_2_4_weeks\",\"\") + \"\\n\")\n",
        "    out.append(\"\\n### Validation Plan\\n\" + artifacts.get(\"validation_plan\",\"\") + \"\\n\")\n",
        "\n",
        "    out.append(\"\\n## 5) 근거 링크(Top)\\n\" + \"\\n\".join([f\"- {u}\" for u in links]) + \"\\n\")\n",
        "    out.append(\"\\n## 6) Guardrail Check\\n\")\n",
        "    out.append(\"```json\\n\" + json.dumps(guards, ensure_ascii=False, indent=2) + \"\\n```\\n\")\n",
        "\n",
        "    return \"\\n\".join(out)\n",
        "\n",
        "def render_node(state: WorkflowState) -> WorkflowState:\n",
        "    logs = state.get(\"logs\", [])\n",
        "    t0 = time.time()\n",
        "\n",
        "    report = render_report(state)\n",
        "    state[\"final_report_markdown\"] = report\n",
        "\n",
        "    logs.append({\"node\":\"render\", \"t\": time.time()-t0, \"report_chars\": len(report)})\n",
        "    state[\"logs\"] = logs\n",
        "    return state\n"
      ],
      "metadata": {
        "id": "qc2F_aHSBjPU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7) Super Graph (LangGraph)\n"
      ],
      "metadata": {
        "id": "YHBx8HL7ay1j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import StateGraph, START, END\n",
        "\n",
        "graph = StateGraph(WorkflowState)\n",
        "\n",
        "graph.add_node(\"intake\", intake_node)\n",
        "graph.add_node(\"structurer\", structurer_node)\n",
        "graph.add_node(\"evidence_builder\", evidence_builder_node)\n",
        "graph.add_node(\"extractor\", extractor_node)\n",
        "graph.add_node(\"analysis\", analysis_node)\n",
        "graph.add_node(\"decision\", decision_node)\n",
        "graph.add_node(\"blueprint\", blueprint_node)\n",
        "graph.add_node(\"guardrail\", guardrail_node)\n",
        "graph.add_node(\"render\", render_node)\n",
        "\n",
        "graph.add_edge(START, \"intake\")\n",
        "graph.add_conditional_edges(\"intake\", route_after_intake, {\"chat_end\": END, \"structurer\": \"structurer\"})\n",
        "graph.add_edge(\"structurer\", \"evidence_builder\")\n",
        "graph.add_edge(\"evidence_builder\", \"extractor\")\n",
        "graph.add_edge(\"extractor\", \"analysis\")\n",
        "graph.add_edge(\"analysis\", \"decision\")\n",
        "graph.add_conditional_edges(\"decision\", route_after_decision, {\"blueprint\": \"blueprint\"})\n",
        "graph.add_edge(\"blueprint\", \"guardrail\")\n",
        "graph.add_edge(\"guardrail\", \"render\")\n",
        "graph.add_edge(\"render\", END)\n",
        "\n",
        "app = graph.compile()\n"
      ],
      "metadata": {
        "id": "ntTKAXZmBk-A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8) Single-Agent Test Logs\n"
      ],
      "metadata": {
        "id": "yjSKNyaaa08d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 아이디어 입력: \"기획서 자체\"를 아이디어로 사용 (사용자 요구사항 반영)\n",
        "IDEA_TEXT = \"\"\"\n",
        "IdeaProof(가칭)는 창업 아이디어를 입력하면 산업 분류 → 시장/경쟁/고객 신호 수집 → 근거 기반 검증 →\n",
        "Go/No-Go/Pivot 결론을 제공하고, 결론에 따라 피벗 제안과 MVP 설계 산출물(ERD, 로드맵, 검증 플랜)을\n",
        "패키지로 생성하는 서비스이다.\n",
        "\"\"\".strip()\n",
        "\n",
        "state0: WorkflowState = {\"request\": {\"raw_request\": IDEA_TEXT, \"language\":\"ko\", \"tone\":\"concise\", \"mode\":\"standard\"}, \"logs\":[]}\n",
        "\n",
        "# 예: intake + structurer만 단독 테스트\n",
        "tmp = intake_node(state0.copy())\n",
        "tmp = structurer_node(tmp)\n",
        "rprint(tmp[\"idea_schema\"])\n",
        "rprint(tmp[\"logs\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        },
        "id": "1qo6qdyCBnpP",
        "outputId": "86f50d5b-cd01-4bcc-8efe-eeee9fc7b83d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m{\u001b[0m\n",
              "    \u001b[32m'problem'\u001b[0m: \u001b[32m'창업 아이디어 검증 과정의 비효율성 및 주관성: 창업자들이 시장 수요와 경쟁 환경을 체계적으로 \u001b[0m\n",
              "\u001b[32m분석하지 못해 실패 확률이 높으며, 검증 과정에 과도한 시간과 비용이 소요됩니다.'\u001b[0m,\n",
              "    \u001b[32m'target'\u001b[0m: \u001b[32m'초기 창업자, 예비 창업자, 스타트업 액셀러레이터, 대학 창업 지원 프로그램'\u001b[0m,\n",
              "    \u001b[32m'solution'\u001b[0m: \u001b[32m'AI 기반 아이디어 자동 검증 플랫폼: 산업 분류부터 신호 수집, 데이터 기반 검증, 결론 도출 및 실행 \u001b[0m\n",
              "\u001b[32m계획 생성까지 원클릭으로 제공하는 SaaS 서비스'\u001b[0m,\n",
              "    \u001b[32m'differentiation'\u001b[0m: \u001b[32m'1\u001b[0m\u001b[32m)\u001b[0m\u001b[32m 3가지 결론\u001b[0m\u001b[32m(\u001b[0m\u001b[32mGo/No-Go/Pivot\u001b[0m\u001b[32m)\u001b[0m\u001b[32m에 따라 맞춤형 피벗 제안 및 MVP 산출물 자동 생성 2\u001b[0m\u001b[32m)\u001b[0m\u001b[32m \u001b[0m\n",
              "\u001b[32mERD/로드맵/검증 플랜 등 실행 단계 문서 패키징 3\u001b[0m\u001b[32m)\u001b[0m\u001b[32m 경쟁사 대비 70% 빠른 검증 프로세스'\u001b[0m,\n",
              "    \u001b[32m'business_model'\u001b[0m: \u001b[32m'Freemium 모델: 기본 검증은 무료 제공, 프리미엄 기능\u001b[0m\u001b[32m(\u001b[0m\u001b[32m고도화된 데이터 분석, 전문가 컨설팅 \u001b[0m\n",
              "\u001b[32m연동, 팀 협업 도구\u001b[0m\u001b[32m)\u001b[0m\u001b[32m은 구독제\u001b[0m\u001b[32m(\u001b[0m\u001b[32m연간 $299-$499\u001b[0m\u001b[32m)\u001b[0m\u001b[32m 또는 검증 보고서 단위 판매\u001b[0m\u001b[32m(\u001b[0m\u001b[32m1회 $49-$99\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m,\n",
              "    \u001b[32m'industry'\u001b[0m: \u001b[32m'기업용 소프트웨어\u001b[0m\u001b[32m(\u001b[0m\u001b[32mSaaS\u001b[0m\u001b[32m)\u001b[0m\u001b[32m / 스타트업 인큐베이팅 서비스 / AI 비즈니스 분석'\u001b[0m,\n",
              "    \u001b[32m'keywords'\u001b[0m: \u001b[1m[\u001b[0m\n",
              "        \u001b[32m'창업 검증'\u001b[0m,\n",
              "        \u001b[32m'AI 시장 분석'\u001b[0m,\n",
              "        \u001b[32m'스타트업 MVP'\u001b[0m,\n",
              "        \u001b[32m'피벗 추천 시스템'\u001b[0m,\n",
              "        \u001b[32m'자동화된 비즈니스 검증'\u001b[0m,\n",
              "        \u001b[32m'SaaS 도구'\u001b[0m,\n",
              "        \u001b[32m'데이터 기반 의사결정'\u001b[0m\n",
              "    \u001b[1m]\u001b[0m,\n",
              "    \u001b[32m'persona_hypotheses'\u001b[0m: \u001b[1m[\u001b[0m\n",
              "        \u001b[32m'예비 창업자의 60%는 사업성 검증 단계에서 전문가 자문 비용 부담으로 포기하는 것으로 추정'\u001b[0m,\n",
              "        \u001b[32m'초기 스타트업의 45%가 시장 조사 없이 제품 개발을 시작해 50% 이상이 2년 내 실패한다는 데이터 존재'\u001b[0m\n",
              "    \u001b[1m]\u001b[0m\n",
              "\u001b[1m}\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'problem'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'창업 아이디어 검증 과정의 비효율성 및 주관성: 창업자들이 시장 수요와 경쟁 환경을 체계적으로 </span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">분석하지 못해 실패 확률이 높으며, 검증 과정에 과도한 시간과 비용이 소요됩니다.'</span>,\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'target'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'초기 창업자, 예비 창업자, 스타트업 액셀러레이터, 대학 창업 지원 프로그램'</span>,\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'solution'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'AI 기반 아이디어 자동 검증 플랫폼: 산업 분류부터 신호 수집, 데이터 기반 검증, 결론 도출 및 실행 </span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">계획 생성까지 원클릭으로 제공하는 SaaS 서비스'</span>,\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'differentiation'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'1) 3가지 결론(Go/No-Go/Pivot)에 따라 맞춤형 피벗 제안 및 MVP 산출물 자동 생성 2) </span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">ERD/로드맵/검증 플랜 등 실행 단계 문서 패키징 3) 경쟁사 대비 70% 빠른 검증 프로세스'</span>,\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'business_model'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Freemium 모델: 기본 검증은 무료 제공, 프리미엄 기능(고도화된 데이터 분석, 전문가 컨설팅 </span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">연동, 팀 협업 도구)은 구독제(연간 $299-$499) 또는 검증 보고서 단위 판매(1회 $49-$99)'</span>,\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'industry'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'기업용 소프트웨어(SaaS) / 스타트업 인큐베이팅 서비스 / AI 비즈니스 분석'</span>,\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'keywords'</span>: <span style=\"font-weight: bold\">[</span>\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'창업 검증'</span>,\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'AI 시장 분석'</span>,\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'스타트업 MVP'</span>,\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'피벗 추천 시스템'</span>,\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'자동화된 비즈니스 검증'</span>,\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'SaaS 도구'</span>,\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'데이터 기반 의사결정'</span>\n",
              "    <span style=\"font-weight: bold\">]</span>,\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'persona_hypotheses'</span>: <span style=\"font-weight: bold\">[</span>\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'예비 창업자의 60%는 사업성 검증 단계에서 전문가 자문 비용 부담으로 포기하는 것으로 추정'</span>,\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'초기 스타트업의 45%가 시장 조사 없이 제품 개발을 시작해 50% 이상이 2년 내 실패한다는 데이터 존재'</span>\n",
              "    <span style=\"font-weight: bold\">]</span>\n",
              "<span style=\"font-weight: bold\">}</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m[\u001b[0m\n",
              "    \u001b[1m{\u001b[0m\u001b[32m'node'\u001b[0m: \u001b[32m'intake'\u001b[0m, \u001b[32m't'\u001b[0m: \u001b[1;36m3.1217169761657715\u001b[0m, \u001b[32m'route'\u001b[0m: \u001b[32m'workflow'\u001b[0m\u001b[1m}\u001b[0m,\n",
              "    \u001b[1m{\u001b[0m\n",
              "        \u001b[32m'node'\u001b[0m: \u001b[32m'structurer'\u001b[0m,\n",
              "        \u001b[32m't'\u001b[0m: \u001b[1;36m3.3858282566070557\u001b[0m,\n",
              "        \u001b[32m'industry'\u001b[0m: \u001b[32m'기업용 소프트웨어\u001b[0m\u001b[32m(\u001b[0m\u001b[32mSaaS\u001b[0m\u001b[32m)\u001b[0m\u001b[32m / 스타트업 인큐베이팅 서비스 / AI 비즈니스 분석'\u001b[0m\n",
              "    \u001b[1m}\u001b[0m\n",
              "\u001b[1m]\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
              "    <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'node'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'intake'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'t'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3.1217169761657715</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'route'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'workflow'</span><span style=\"font-weight: bold\">}</span>,\n",
              "    <span style=\"font-weight: bold\">{</span>\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'node'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'structurer'</span>,\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'t'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3.3858282566070557</span>,\n",
              "        <span style=\"color: #008000; text-decoration-color: #008000\">'industry'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'기업용 소프트웨어(SaaS) / 스타트업 인큐베이팅 서비스 / AI 비즈니스 분석'</span>\n",
              "    <span style=\"font-weight: bold\">}</span>\n",
              "<span style=\"font-weight: bold\">]</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9) Super Graph End-to-End Run Logs\n"
      ],
      "metadata": {
        "id": "d-qFd1M4a3kY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 실행 + 진행상황(노드별) 출력: 어디서 오래 걸리는지 바로 보이게 함\n",
        "state_init: WorkflowState = {\"request\": {\"raw_request\": IDEA_TEXT, \"language\":\"ko\", \"tone\":\"concise\", \"mode\":\"standard\"}, \"logs\":[]}\n",
        "\n",
        "last_log_len = 0\n",
        "final_state = None\n",
        "\n",
        "for s in app.stream(state_init, stream_mode=\"values\"):\n",
        "    logs = s.get(\"logs\", [])\n",
        "    if len(logs) > last_log_len:\n",
        "        for item in logs[last_log_len:]:\n",
        "            print(\"[LOG]\", item)\n",
        "        last_log_len = len(logs)\n",
        "    final_state = s\n",
        "\n",
        "print(\"\\n\\n================ FINAL REPORT (markdown) ================\\n\")\n",
        "print((final_state or {}).get(\"final_report_markdown\",\"\")[:4000])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hG1YeRdiBtZK",
        "outputId": "88f87807-68c3-479e-dd68-0318bbd28f1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LOG] {'node': 'intake', 't': 2.6452674865722656, 'route': 'workflow'}\n",
            "[LOG] {'node': 'structurer', 't': 2.6188158988952637, 'industry': 'AI SaaS/스타트업 인큐베이션/비즈니스 인텔리전스'}\n",
            "[LOG] {'node': 'evidence_builder', 't': 457.4857060909271, 'cache': 'MISS', 'collection': 'ideaproof_35b91439639a2ad8', 'mode': 'standard', 'sources': 51, 'stored_chunks': 108, 'time_budget_sec': 720, 'time_budget_hit': False}\n",
            "[LOG] {'node': 'extractor', 't': 35.4906370639801, 'questions': 5}\n",
            "[LOG] {'node': 'analysis', 't': 4.323936223983765, 'score': {'market': 3.0, 'competition': 2.5, 'customer': 3.5, 'risks': 2.0}}\n",
            "[LOG] {'node': 'decision', 't': 4.2830810546875, 'decision': 'GO'}\n",
            "[LOG] {'node': 'blueprint', 't': 7.513864040374756}\n",
            "[LOG] {'node': 'guardrail', 't': 2.804211139678955, 'flags': {'policy_violation': False, 'token_overflow': False, 'copyright_risk': False, 'evidence_insufficient': False}}\n",
            "[LOG] {'node': 'render', 't': 0.0003123283386230469, 'report_chars': 6034}\n",
            "\n",
            "\n",
            "================ FINAL REPORT (markdown) ================\n",
            "\n",
            "# IdeaProof 결과 리포트 (Prototype)\n",
            "\n",
            "## 1) 아이디어 구조화\n",
            "\n",
            "- 문제: 창업 아이디어 검증 과정의 주관성, 시간/비용 과다, 실패 리스크 관리 부재\n",
            "- 대상: 초기 창업자/스타트업, 벤처 캐피탈, 대학 창업지원단, 액셀러레이터\n",
            "- 해결: AI 기반 자동 검증 시스템과 데이터 기반 의사결정 지원 도구 제공. 산업 분류부터 MVP 설계까지 종합 솔루션 패키지화\n",
            "- 차별: 1) 실시간 경쟁 신호 분석(특허/트렌드/소셜 데이터 연동), 2) 검증 결과에 따른 동적 피벗 제안, 3) 실행 가능한 기술 문서 자동 생성(ERD/로드맵 등)\n",
            "- BM: SaaS 구독 + 프리미엄 검증 리포트 유료화 + 액셀러레이터 파트너십 수수료\n",
            "- 산업: AI SaaS/스타트업 인큐베이션/비즈니스 인텔리전스\n",
            "- 키워드: 아이디어 검증, 스타트업 분석, 경쟁 신호 수집, AI 기반 의사결정, MVP 설계 자동화, 피벗 제안, 산업 분류 시스템\n",
            "\n",
            "\n",
            "## 2) 신호(시장/경쟁/고객/리스크)\n",
            "\n",
            "### Market\n",
            "fact: 국내 스타트업 실패 사례의 42%는 시장 수요 부족(No Market Need)으로 집중됨(CB Insights, platum.kr). interpretation: 국내 창업 생태계에서 시장 니즈와 제품 간 괴리가 심각함을 시사. hypothesis: AI 기반 실시간 시장 신호 분석(특허/트렌드/소셜 데이터 연동)은 검증 과정의 주관성과 시간/비용 문제를 해결할 수 있는 핵심 기능.\n",
            "\n",
            "### Competition\n",
            "fact: 국내 창업지원기관의 검증 도구는 양적 성장에 집중하나 질적 검증 기능이 부재(한국직업능력연구원, KRIVET). interpretation: 기존 도구들은 MVP 개발 지원, 동적 피벗 제안 등 AI SaaS 솔루션의 차별화 요소를 제공하지 못함. hypothesis: 경쟁사 대비 실시간 데이터 연동과 자동 문서 생성(ERD/로드맵) 기능이 시장 진입 장벽을 낮출 것.\n",
            "\n",
            "### Customer\n",
            "fact: 초기 창업자의 70% 이상이 복잡한 시장 분석 대신 1-click 검증 결과를 선호하는 것으로 나타남(platum.kr). interpretation: 타겟 고객(초기 창업자, VC)이 빠른 의사결정과 실행 가능한 인사이트를 요구. hypothesis: AI 기반 종합 솔루션 패키지는 SaaS 구독 모델로 고객 니즈를 충족시킬 수 있음.\n",
            "\n",
            "### Risks\n",
            "fact: 국내 창업 문화는 실패를 낙인으로 인식하며, 빠른 실패(Fail Fast) 문화가 부재(이코노미스트). interpretation: AI 검증 결과에 따른 피벗 제안이 국내 창업자와 VC에게 저항받을 가능성 존재. hypothesis: 실증 데이터(CB Insights 등)를 기반으로 한 설명 가능한 점수 시스템이 리스크 관리를 지원할 것.\n",
            "\n",
            "\n",
            "**Explainable Score(0~5):** {\"market\": 3.0, \"competition\": 2.5, \"customer\": 3.5, \"risks\": 2.0}\n",
            "\n",
            "\n",
            "## 3) 결론\n",
            "\n",
            "**Decision:** GO\n",
            "\n",
            "\n",
            "**Key reasons**\n",
            "- 국내 스타트업 실패 사례의 42%가 시장 수요 부족(CB Insights)으로, AI 기반 실시간 시장 신호 분석이 검증 과정의 주관성/시간/비용 문제 해결에 기여할 수 있음\n",
            "- 기존 창업지원기관의 검증 도구는 MVP 개발 지원에 집중되어 있으며, 동적 피벗 제안 및 자동 문서 생성과 같은 AI SaaS 솔루션의 차별화 요소가 경쟁사 대비 우위 확보 가능\n",
            "- 초기 창업자의 70% 이상이 1-click 검증 결과를 선호하는 것으로 나타나, SaaS 구독 모델로 고객 니즈를 충족시킬 수 있는 높은 시장 적합성 존재\n",
            "\n",
            "\n",
            "**Next actions**\n",
            "- POC(Proof of Concept) 개발: 특허/트렌드/소셜 데이터 연동을 통한 실시간 경쟁 신호 분석 모듈 프로토타입 구현\n",
            "- 검증 실험: 초기 창업자 대상으로 MVP 설계 자동화 기능 테스트(ERD/로드맵 생성 정확도 및 실행 가능성 평가)\n",
            "- 파트너십 탐색: 대학 창업지원단 및 액셀러레이터와 협업하여 동적 피벗 제안 시스템의 현장 적용성 검증\n",
            "\n",
            "\n",
            "## 4) MVP 설계 산출물\n",
            "\n",
            "### PRD 1p\n",
            "AI 기반 스타트업 아이디어 검증 SaaS 플랫폼. 특허/트렌드/소셜 데이터를 연동해 실시간 시장 신호를 분석하고, 실행 가능한 MVP 설계 문서(ERD/로드맵)를 자동 생성하며, 검증 결과에 따른 동적 피벗 전략을 제안하는 종합 솔루션.\n",
            "\n",
            "\n",
            "### Scope (Must / Should / Could)\n",
            "### Must have\n",
            "- 실시간 경쟁 신호 분석 모듈(특허/트렌드/소셜 데이터 연동)\n",
            "- 1-click 아이디어 검증 리포트 생성\n",
            "- MVP 설계 자동화(ERD/기술 로드맵) 기능\n",
            "\n",
            "### Should have\n",
            "- 산업 분류 시스템 자동 매핑\n",
            "- 피벗 제안 알고리즘(데이터 기반 대안 생성)\n",
            "- SaaS 기본 구독 모델(결제/사용자 관리)\n",
            "\n",
            "### Could have\n",
            "- 실시간 경쟁사 모니터링 대시보드\n",
            "- 액셀러레이터 전용 협업 툴 연동\n",
            "- 실패 사례 데이터베이스(학습용)\n",
            "\n",
            "\n",
            "### ERD (Mermaid)\n",
            "```mermaid\n",
            "ern\n",
            "    Users {\n",
            "        int id PK\n",
            "        varchar email\n",
            "        varchar role\n",
            "        datetime created_at\n",
            "    }\n",
            "    Ideas {\n",
            "        int id PK\n",
            "        varchar title\n",
            "        text description\n",
            "        int industry_id FK\n",
            "        float validation_score\n",
            "    }\n",
            "    Industries {\n",
            "        int id PK\n",
            "        varchar name\n",
            "        text market_trends\n",
            "    }\n",
            "    ValidationReports {\n",
            "        int id PK\n",
            "        int idea_id FK\n",
            "        text signal_analysis\n",
            "        text pivot_recommendations\n",
            "        datetime generated_at\n",
            "    }\n",
            "    ERDs {\n",
            "        int id PK\n",
            "        int idea_id FK\n",
            "        text diagram_mermaid\n",
            "    }\n",
            "    Roadmaps {\n",
            "        int id PK\n",
            "        int idea_id FK\n",
            "        text phases\n",
            "    }\n",
            "\n",
            "    Users ||--o{ Ideas : proposes\n",
            "    Ideas }|--|| Industries : classified\n",
            "    Ideas ||--o{ ValidationReports : generates\n",
            "    Ideas ||--o{ ERDs : generates\n",
            "    Ideas ||--o{ Roadmaps : generates\n",
            "```\n",
            "\n",
            "\n",
            "### User Flow\n",
            "1. 사용자 등록/로그인(SaaS)\n",
            "2. 아이디어 제목 및 설명 입력\n",
            "3. 산업 분류 시스템 자동 매핑\n",
            "4. 1-click 검증 실행 → 실시간 데이터 수집(특허/트렌드/소셜)\n",
            "5. 검증 리포트 생성(시장 적합성 점수, 경쟁 신호 분석)\n",
            "6. 피벗 제안(필요시 대안 전략 생성)\n",
            "7. MVP 설계 문서 자동 생성(ERD/기술 로드맵)\n",
            "8. 문서화 결과 다운로드 또는 편집\n",
            "9. 구독 모델별 프리미엄 기능 추가(실시간 모니터링 등)\n",
            "\n",
            "\n",
            "### Roadmap (2~4 weeks)\n",
            "**Week 1-2: Core Validation Engine**\n",
            "- 실시간 데이터 수집 API 연동(특허청/구글 트렌드/소셜 미디어)\n",
            "- 검증 알고리즘 개발(시장 적합성 점수 계산)\n",
            "\n",
            "**Week 3-4: MVP Automation**\n",
            "- ERD 생성기 개발(Mermaid 템플릿 기반)\n",
            "- 기술 로드맵 자동 생성 모듈(단계별 작업 분할)\n",
            "\n",
            "**Week 5-6: Pivot Recommendation**\n",
            "- 실패 사례 DB 구축(CB Insights 데이터 활용)\n",
            "- 대안 생성 알고리즘 개발(유사 산업 사례 매핑)\n",
            "\n",
            "**Week 7-8: Sa\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10) (Optional) Save report as Markdown file\n"
      ],
      "metadata": {
        "id": "7msZKrxKa5FQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "out_path = \"ideaproof_report.md\"\n",
        "with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(final_state.get(\"final_report_markdown\",\"\"))\n",
        "print(\"saved:\", out_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39seufegBwAu",
        "outputId": "76f52da3-25d5-450f-a81f-3d0f8d442417"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "saved: ideaproof_report.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (Optional) Step1/Step2 수행 요약 (제출용)\n",
        "\n",
        "### Step 1) Vanilla Python vs LangGraph 비교 (내 구현 기준)\n",
        "**공통점**\n",
        "- LLM(Upstage) 호출 + Tool(Web search/Download/PDF parse/VectorDB/Rerank) 조합으로 근거 수집 → 요약/판단\n",
        "- 상태(요청/중간 산출물/로그)를 누적하며 최종 리포트 생성\n",
        "\n",
        "**차이점**\n",
        "- Vanilla: 순차 호출/예외처리/토큰 관리 등을 코드 흐름으로 직접 제어(단순하지만 규모 커지면 유지보수 비용↑)\n",
        "- LangGraph: 노드/엣지로 제어 흐름이 명확하고, 실행 흐름 추적(stream)과 디버깅이 쉬움(구성 초기 비용은↑)\n",
        "\n",
        "### Step 2) Query 생성(Expansion) 및 search→rerank 관찰\n",
        "- Evidence Builder(검색) 단계에서 mode(standard/deep)에 따라 검색 쿼리 다양화/확장 정도가 달라짐\n",
        "- Extractor 단계에서 VectorDB 후보를 가져온 뒤 LLM-as-Judge로 rerank하여 최종 근거를 좁힘\n",
        "- 관찰 포인트(로그):\n",
        "  - 생성된 queries 목록(다양성/키워드 커버리지)\n",
        "  - 수집된 소스 수 및 chunk 수\n",
        "  - rerank 상위 근거의 점수 분포(상위-하위 격차)\n"
      ],
      "metadata": {
        "id": "lP2a5oD6cmIE"
      }
    }
  ]
}